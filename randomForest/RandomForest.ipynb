{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKpwWFCYGFAU"
   },
   "source": [
    "## CMPT825 Project: Tokenization + Random Forest\n",
    "\n",
    "1. load the tweet data\n",
    "2. Label the data, split train and test data\n",
    "3. Random forest models for CA and USA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYfK4O6tdfRv",
    "outputId": "0d3c3259-d5c3-4439-f4f6-ab276496f348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbT62TpQdQ1D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from textblob import TextBlob\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dir to data/usa/ to data/ca to calculate the ca results\n",
    "X_train = np.load('data/usa/x_tr.npy')\n",
    "Y_train = np.load('data/usa/x_test.npy')\n",
    "X_test = np.load('data/usa/x_test.npy')\n",
    "Y_test = np.load('data/usa/x_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKYxy9xCjQFD",
    "outputId": "e5903698-1db6-4f7e-d4df-43f95a1e2056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/7  acc:  0.4546777533449158  precision:  0.8203071918713251  recall:  0.4319187104080053  f1:  0.5505599581950936\n",
      "step 1/7  acc:  0.376474510206175  precision:  0.7750905863182295  recall:  0.3511492960647955  f1:  0.46178091429033746\n",
      "step 2/7  acc:  0.4881621715186911  precision:  0.8727379396502423  recall:  0.46115237128824144  f1:  0.5855719322353964\n",
      "step 2/7  acc:  0.384372756180121  precision:  0.8150656756355655  recall:  0.35752031870290746  f1:  0.4733476687650904\n",
      "step 3/7  acc:  0.49030984145708184  precision:  0.894395906325235  recall:  0.4571065797180305  f1:  0.5811135072041723\n",
      "step 3/7  acc:  0.38780900605190277  precision:  0.8257357142478671  recall:  0.35918872050269995  f1:  0.4745193535927587\n",
      "step 4/7  acc:  0.48739285691389445  precision:  0.9048563682619418  recall:  0.4508739377380002  f1:  0.5742636440631301\n",
      "step 4/7  acc:  0.39104010667760797  precision:  0.830323543979345  recall:  0.3618410153316313  f1:  0.4776480908005973\n",
      "step 5/7  acc:  0.4833860100139118  precision:  0.9163505236835783  recall:  0.44548337802129173  f1:  0.5704922487455267\n",
      "step 5/7  acc:  0.38724484562519235  precision:  0.8337487198149853  recall:  0.35814139606807505  f1:  0.47466258581117576\n",
      "step 6/7  acc:  0.48248847630831565  precision:  0.9229720740347381  recall:  0.44376346131863603  f1:  0.5694810914313345\n",
      "step 6/7  acc:  0.3891681198071597  precision:  0.8352126481928752  recall:  0.3596451815439237  f1:  0.4760477132875484\n",
      "step 7/7  acc:  0.4822512709718367  precision:  0.927254029856861  recall:  0.44302641573109325  f1:  0.5692272259365552\n",
      "step 7/7  acc:  0.3896040619550723  precision:  0.8356666622608725  recall:  0.35994760319275354  f1:  0.4762415746049095\n",
      "504.74720430374146\n"
     ]
    }
   ],
   "source": [
    "# USA\n",
    "print(\"############USA RF############\")\n",
    "batch_size = 20000\n",
    "num_batch = X_train.shape[0] // batch_size\n",
    "acc_change = []\n",
    "precision_change = []\n",
    "recall_change = []\n",
    "f1_change = []\n",
    "model = RandomForestClassifier(n_estimators=200, warm_start=True)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0, num_batch):\n",
    "  model.n_estimators += 200\n",
    "  model.fit(X_train[i * batch_size : (i+1) * batch_size], \n",
    "            Y_train[i * batch_size : (i+1) * batch_size])\n",
    "  y_pred = model.predict(X_train)\n",
    "  precision = precision_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  recall = recall_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  acc = accuracy_score(y_true=Y_train, y_pred=y_pred)\n",
    "  f1 = f1_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  print(\"step %d/%d\" % (i+1, num_batch), \n",
    "        \" acc: \", acc, \n",
    "        \" precision: \", precision,\n",
    "        \" recall: \", recall,\n",
    "        \" f1: \", f1)\n",
    "  \n",
    "  y_pred = model.predict(X_test)\n",
    "  precision = precision_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "  recall = recall_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "  acc = accuracy_score(y_true=Y_test, y_pred=y_pred)\n",
    "  f1 = f1_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "\n",
    "  precision_change.append(precision)\n",
    "  acc_change.append(acc)\n",
    "  f1_change.append(f1)\n",
    "\n",
    "  print(\"step %d/%d\" % (i+1, num_batch), \n",
    "        \" acc: \", acc, \n",
    "        \" precision: \", precision,\n",
    "        \" recall: \", recall,\n",
    "        \" f1: \", f1)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zVbQPTdDzqA",
    "outputId": "72c81508-232a-45b8-81c2-6c7a50a75e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/4  acc:  0.5432316436608282  precision:  0.8023876675508791  recall:  0.4808536222892017  f1:  0.5625515639467932\n",
      "step 1/4  acc:  0.4075070755811256  precision:  0.5966751095749955  recall:  0.32374896784910745  f1:  0.3611315183391912\n",
      "step 2/4  acc:  0.583169005915787  precision:  0.8597634477578744  recall:  0.5101137634633154  f1:  0.5966390976030066\n",
      "step 2/4  acc:  0.408991787686169  precision:  0.6768011272385343  recall:  0.3249137191340144  f1:  0.36545485294264685\n",
      "step 3/4  acc:  0.5620461663380119  precision:  0.8807807593628253  recall:  0.46392598802717333  f1:  0.533305933215645\n",
      "step 3/4  acc:  0.41210040365610356  precision:  0.6976377519665222  recall:  0.32653774615508174  f1:  0.36699827979673433\n",
      "step 4/4  acc:  0.5608746085140935  precision:  0.8883530215824024  recall:  0.45295231995974317  f1:  0.5128653923893354\n",
      "step 4/4  acc:  0.4136315130144295  precision:  0.7063190636231722  recall:  0.32785662957942013  f1:  0.36886552884255264\n",
      "144.4937903881073\n"
     ]
    }
   ],
   "source": [
    "# CA\n",
    "print(\"############CA RF############\")\n",
    "batch_size = 20000\n",
    "num_batch = X_train.shape[0] // batch_size\n",
    "acc_change = []\n",
    "precision_change = []\n",
    "recall_change = []\n",
    "f1_change = []\n",
    "model = RandomForestClassifier(n_estimators=200, warm_start=True)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0, num_batch):\n",
    "  model.n_estimators += 200\n",
    "  model.fit(X_train[i * batch_size : (i+1) * batch_size], \n",
    "            Y_train[i * batch_size : (i+1) * batch_size])\n",
    "  y_pred = model.predict(X_train)\n",
    "  precision = precision_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  recall = recall_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  acc = accuracy_score(y_true=Y_train, y_pred=y_pred)\n",
    "  f1 = f1_score(y_true=Y_train, y_pred=y_pred, average='macro')\n",
    "  print(\"step %d/%d\" % (i+1, num_batch), \n",
    "        \" acc: \", acc, \n",
    "        \" precision: \", precision,\n",
    "        \" recall: \", recall,\n",
    "        \" f1: \", f1)\n",
    "  \n",
    "  y_pred = model.predict(X_test)\n",
    "  precision = precision_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "  recall = recall_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "  acc = accuracy_score(y_true=Y_test, y_pred=y_pred)\n",
    "  f1 = f1_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
    "\n",
    "  precision_change.append(precision)\n",
    "  acc_change.append(acc)\n",
    "  f1_change.append(f1)\n",
    "\n",
    "  print(\"step %d/%d\" % (i+1, num_batch), \n",
    "        \" acc: \", acc, \n",
    "        \" precision: \", precision,\n",
    "        \" recall: \", recall,\n",
    "        \" f1: \", f1)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfbtAjnPzoBL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
